{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading AI paper dataset...\n",
      "Loaded 16431 NIPS papers from 2010 onwards (out of 20284 total)\n",
      "Loaded 12128 CVPR papers from 2010 onwards (out of 12128 total)\n",
      "Loaded 5806 ICLR papers from 2010 onwards (out of 5806 total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering NIPS papers for 'attention': 100%|██████████| 16431/16431 [00:07<00:00, 2160.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1883 NIPS papers with 'attention' mentioned at least 3 times since 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering CVPR papers for 'attention': 100%|██████████| 12128/12128 [00:05<00:00, 2150.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3404 CVPR papers with 'attention' mentioned at least 3 times since 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering ICLR papers for 'attention': 100%|██████████| 5806/5806 [00:04<00:00, 1359.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1221 ICLR papers with 'attention' mentioned at least 3 times since 2010\n",
      "\n",
      "Attention papers by conference:\n",
      "conference\n",
      "CVPR    3404\n",
      "NIPS    1883\n",
      "ICLR    1221\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Attention papers by year:\n",
      "year\n",
      "2010       2\n",
      "2011       1\n",
      "2012       4\n",
      "2013      17\n",
      "2014      14\n",
      "2015      30\n",
      "2016      75\n",
      "2017     143\n",
      "2018      97\n",
      "2019     166\n",
      "2020     252\n",
      "2021     909\n",
      "2022    1367\n",
      "2023    1871\n",
      "2024    1560\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average 'attention' mentions by conference:\n",
      "conference\n",
      "CVPR    21.348707\n",
      "ICLR    28.260442\n",
      "NIPS    24.936803\n",
      "Name: attention_count, dtype: float64\n",
      "\n",
      "Pivot table of attention papers by year and conference:\n",
      "conference  CVPR  ICLR  NIPS\n",
      "year                        \n",
      "2010           0     0     2\n",
      "2011           0     0     1\n",
      "2012           0     0     4\n",
      "2013          15     0     2\n",
      "2014           9     0     5\n",
      "2015          16     4    10\n",
      "2016          42    12    21\n",
      "2017          93    21    29\n",
      "2018           0    34    63\n",
      "2019           0    54   112\n",
      "2020           0    78   174\n",
      "2021         459   122   328\n",
      "2022         772   152   443\n",
      "2023         915   267   689\n",
      "2024        1083   477     0\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading AI paper dataset...\")\n",
    "ds = load_dataset(\"Seed42Lab/AI-paper-crawl\")\n",
    "\n",
    "# Focus only on NIPS, CVPR, and ICLR papers from 2010 onwards\n",
    "conferences = [\"NIPS\", \"CVPR\", \"ICLR\"]\n",
    "filtered_data = {}\n",
    "\n",
    "for conf in conferences:\n",
    "    conf_data = ds[conf]\n",
    "    # Convert year to int if it's a string and filter by year ≥ 2010\n",
    "    filtered_data[conf] = []\n",
    "    for paper in conf_data:\n",
    "        # Convert year to int if it's a string\n",
    "        year = paper[\"year\"]\n",
    "        if isinstance(year, str):\n",
    "            try:\n",
    "                year = int(year)\n",
    "            except ValueError:\n",
    "                # Skip papers with invalid year format\n",
    "                continue\n",
    "        \n",
    "        # Only include papers from 2010 onwards\n",
    "        if year >= 2010:\n",
    "            # Create a copy with year as int\n",
    "            paper_copy = dict(paper)\n",
    "            paper_copy[\"year\"] = year\n",
    "            filtered_data[conf].append(paper_copy)\n",
    "    \n",
    "    print(f\"Loaded {len(filtered_data[conf])} {conf} papers from 2010 onwards (out of {len(conf_data)} total)\")\n",
    "\n",
    "# Function to filter papers containing the word \"attention\" at least 3 times\n",
    "def filter_attention_papers(data_by_conference):\n",
    "    all_attention_papers = []\n",
    "    \n",
    "    # Process each conference separately\n",
    "    for conference_name, conference_data in data_by_conference.items():\n",
    "        conference_attention_papers = []\n",
    "        \n",
    "        for paper in tqdm(conference_data, desc=f\"Filtering {conference_name} papers for 'attention'\"):\n",
    "            # Check if \"attention\" appears in the text (case insensitive) at least 3 times\n",
    "            if paper[\"text\"]:\n",
    "                matches = re.findall(r'\\battention\\b', paper[\"text\"], re.IGNORECASE)\n",
    "                if len(matches) >= 5:  # At least 5 occurrences\n",
    "                    # Extract title from text\n",
    "                    title = extract_title(paper[\"text\"])\n",
    "                    \n",
    "                    # Create a record with relevant information\n",
    "                    paper_info = {\n",
    "                        \"conference\": conference_name,\n",
    "                        \"year\": paper[\"year\"],\n",
    "                        \"title\": title,\n",
    "                        \"paper_id\": paper[\"No\"],\n",
    "                        \"index\": paper[\"index\"],\n",
    "                        \"text\": paper[\"text\"],\n",
    "                        \"attention_count\": len(matches)  # Count of \"attention\" occurrences\n",
    "                    }\n",
    "                    conference_attention_papers.append(paper_info)\n",
    "        \n",
    "        print(f\"Found {len(conference_attention_papers)} {conference_name} papers with 'attention' mentioned at least 3 times since 2010\")\n",
    "        all_attention_papers.extend(conference_attention_papers)\n",
    "    \n",
    "    return all_attention_papers\n",
    "\n",
    "# Helper function to extract paper title from text\n",
    "def extract_title(text):\n",
    "    if not text:\n",
    "        return \"Unknown Title\"\n",
    "    \n",
    "    # Try to extract the first line or sentence as the title\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and len(line) > 10 and len(line) < 200:  # Reasonable title length\n",
    "            return line\n",
    "    \n",
    "    # Fallback: just take the first 100 characters\n",
    "    return text[:100] + \"...\" if len(text) > 100 else text\n",
    "\n",
    "# Filter papers with \"attention\"\n",
    "attention_papers = filter_attention_papers(filtered_data)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "attention_df = pd.DataFrame(attention_papers)\n",
    "\n",
    "# Display stats by conference\n",
    "print(\"\\nAttention papers by conference:\")\n",
    "conference_counts = attention_df['conference'].value_counts()\n",
    "print(conference_counts)\n",
    "\n",
    "# Display stats by year\n",
    "print(\"\\nAttention papers by year:\")\n",
    "year_counts = attention_df['year'].value_counts().sort_index()\n",
    "print(year_counts)\n",
    "\n",
    "# Show average attention count by conference\n",
    "average_attention = attention_df.groupby('conference')['attention_count'].mean()\n",
    "print(\"\\nAverage 'attention' mentions by conference:\")\n",
    "print(average_attention)\n",
    "\n",
    "# Create a pivot table to analyze trends by conference and year\n",
    "attention_pivot = pd.pivot_table(\n",
    "    attention_df, \n",
    "    values='index', \n",
    "    index='year', \n",
    "    columns='conference', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nPivot table of attention papers by year and conference:\")\n",
    "print(attention_pivot)\n",
    "\n",
    "# Store data by conference for easier access\n",
    "attention_by_conference = {}\n",
    "for conf in conferences:\n",
    "    attention_by_conference[conf] = attention_df[attention_df['conference'] == conf]\n",
    "\n",
    "# Identify potential breakthrough papers - early mentions of attention\n",
    "early_attention_papers = {}\n",
    "for conf in conferences:\n",
    "    conf_df = attention_by_conference[conf]\n",
    "    if not conf_df.empty:\n",
    "        # Sort by year and then by attention count (descending) to find influential early papers\n",
    "        early_attention_papers[conf] = conf_df[conf_df['year'] <= 2015].sort_values(['year', 'attention_count'], \n",
    "                                                                                     ascending=[True, False]).head(5)\n",
    "    else:\n",
    "        early_attention_papers[conf] = pd.DataFrame()  # Empty DataFrame if no papers match\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication by Attention Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing papers for different senses of 'attention'...\n",
      "Columns in DataFrame: ['conference', 'year', 'title', 'paper_id', 'index', 'text', 'attention_count']\n",
      "\n",
      "Paper Classification Summary:\n",
      "primary_category\n",
      "mechanism        5285\n",
      "explanatory       925\n",
      "cognitive         243\n",
      "general_usage      55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "General vs Technical Usage:\n",
      "General language usage: 55 papers (0.8%)\n",
      "Technical AI usage: 6453 papers (99.2%)\n",
      "\n",
      "Distribution of technical usage by conference:\n",
      "primary_category  cognitive  explanatory  mechanism\n",
      "conference                                         \n",
      "CVPR                     97          472       2812\n",
      "ICLR                     42          176        992\n",
      "NIPS                    104          277       1481\n",
      "\n",
      "Evolution of technical usage over time:\n",
      "primary_category  cognitive  explanatory  mechanism\n",
      "year                                               \n",
      "2010                      1            1          0\n",
      "2011                      1            0          0\n",
      "2012                      2            2          0\n",
      "2013                      4           12          0\n",
      "2014                      6            7          0\n",
      "2015                     13           16          1\n",
      "2016                     41           21         10\n",
      "2017                     45           47         46\n",
      "2018                     23           24         44\n",
      "2019                     15           30        117\n",
      "2020                     20           56        175\n",
      "2021                     26          193        678\n",
      "2022                     20          163       1174\n",
      "2023                     18          197       1649\n",
      "2024                      8          156       1391\n",
      "\n",
      "Average confidence by category:\n",
      "primary_category\n",
      "cognitive        0.441925\n",
      "explanatory      0.581168\n",
      "general_usage    1.000000\n",
      "mechanism        0.739492\n",
      "Name: confidence, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define keyword lexicons for each attention category\n",
    "attention_mechanism_keywords = [\n",
    "    \"self-attention\", \"self attention\", \"multi-head\", \"multi head\", \n",
    "    \"attention layer\", \"attention module\", \"attention network\", \n",
    "    \"attention weights\", \"attention score\", \"attention vector\",\n",
    "    \"scaled dot-product\", \"dot product attention\", \n",
    "    \"additive attention\", \"multiplicative attention\",\n",
    "    \"query-key-value\", \"qkv\", \n",
    "    \"transformer\", \"attention is all you need\",\n",
    "]\n",
    "\n",
    "attention_cognitive_keywords = [\n",
    "    \"cognitive attention\", \"selective attention\", \"attentional resources\",\n",
    "    \"visual attention\", \"human attention\", \"attentional focus\", \n",
    "    \"attentional bias\", \"attention allocation\",\n",
    "    \"cognitive load\", \"attentional control\", \"human-like attention\",\n",
    "    \"biological attention\", \"neuroscience\", \"cognitive science\", \"psychology of attention\",\n",
    "    \"attentional process\", \"attention model\", \"attention theory\", \n",
    "    \"perceptual attention\", \"attentional spotlight\", \"focus of attention\"\n",
    "]\n",
    "\n",
    "attention_explanatory_keywords = [\n",
    "    \"attention visualization\", \"attention map\", \"attention heatmap\", \n",
    "    \"visualize attention\", \"attention rollout\", \"attention flow\",\n",
    "    \"interpretability\", \"explainability\", \"explain\", \"visualize\", \n",
    "    \"attention interpretation\", \"attention analysis\", \"attention pattern\",\n",
    "    \"attention behavior\", \"attention activation\", \"attention highlighting\",\n",
    "    \"attribution\", \"saliency\", \"feature importance\", \"what model attends to\",\n",
    "    \"attention-based explanation\", \"attention for understanding\"\n",
    "]\n",
    "\n",
    "# Patterns for general language usage of \"attention\"\n",
    "general_attention_patterns = [\n",
    "    r\"receives?\\s+attention\",\n",
    "    r\"pays?\\s+attention\",\n",
    "    r\"draws?\\s+attention\",\n",
    "    r\"attention\\s+of\\s+researchers\",\n",
    "    r\"attention\\s+in\\s+the\\s+literature\",\n",
    "    r\"has\\s+received\\s+attention\",\n",
    "    r\"give\\s+attention\\s+to\",\n",
    "    r\"gave\\s+attention\\s+to\",\n",
    "    r\"giving\\s+attention\\s+to\",\n",
    "    r\"brings?\\s+attention\\s+to\",\n",
    "    r\"brought\\s+attention\\s+to\",\n",
    "    r\"bringing\\s+attention\\s+to\",\n",
    "    r\"focus\\s+attention\\s+on\",\n",
    "    r\"focused\\s+attention\\s+on\",\n",
    "    r\"call\\s+attention\\s+to\",\n",
    "    r\"calls\\s+attention\\s+to\",\n",
    "    r\"called\\s+attention\\s+to\",\n",
    "    r\"devote\\s+attention\\s+to\",\n",
    "    r\"devoted\\s+attention\\s+to\",\n",
    "    r\"directing\\s+attention\\s+to\",\n",
    "    r\"direct\\s+attention\\s+to\",\n",
    "    r\"directed\\s+attention\\s+to\",\n",
    "    r\"attract\\s+attention\",\n",
    "    r\"attracts\\s+attention\",\n",
    "    r\"attracted\\s+attention\",\n",
    "    r\"get\\s+attention\",\n",
    "    r\"gets\\s+attention\",\n",
    "    r\"got\\s+attention\",\n",
    "    r\"attention\\s+to\\s+detail\",\n",
    "    r\"attention\\s+span\",\n",
    "    r\"lack\\s+of\\s+attention\",\n",
    "    r\"short\\s+attention\",\n",
    "    r\"limited\\s+attention\",\n",
    "    r\"insufficient\\s+attention\",\n",
    "    r\"enough\\s+attention\"\n",
    "]\n",
    "\n",
    "def classify_attention_paper(text, title=\"\"):\n",
    "    \"\"\"\n",
    "    Classify a paper based on which sense of attention it predominantly uses.\n",
    "    Returns a dictionary with scores for each category.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {\n",
    "            \"mechanism\": 0,\n",
    "            \"cognitive\": 0,\n",
    "            \"explanatory\": 0,\n",
    "            \"primary_category\": \"unknown\",\n",
    "            \"confidence\": 0,\n",
    "            \"mechanism_count\": 0,\n",
    "            \"cognitive_count\": 0,\n",
    "            \"explanatory_count\": 0,\n",
    "            \"general_usage_count\": 0,\n",
    "            \"total_attention_mentions\": 0\n",
    "        }\n",
    "    \n",
    "    # Combine title and text, giving more weight to title\n",
    "    full_text = (title + \" \" + title + \" \" + text).lower()\n",
    "    \n",
    "    # Count matches for each category\n",
    "    mechanism_count = sum(full_text.count(keyword.lower()) for keyword in attention_mechanism_keywords)\n",
    "    cognitive_count = sum(full_text.count(keyword.lower()) for keyword in attention_cognitive_keywords)\n",
    "    explanatory_count = sum(full_text.count(keyword.lower()) for keyword in attention_explanatory_keywords)\n",
    "    \n",
    "    # Count general language usage of \"attention\"\n",
    "    general_usage_count = sum(len(re.findall(pattern, full_text)) for pattern in general_attention_patterns)\n",
    "    \n",
    "    # Count total mentions of \"attention\"\n",
    "    total_attention_mentions = len(re.findall(r'\\battention\\b', full_text))\n",
    "    \n",
    "    # Calculate technical mentions (mechanism + cognitive + explanatory)\n",
    "    # This is a rough approximation\n",
    "    technical_mentions = mechanism_count + cognitive_count + explanatory_count\n",
    "    \n",
    "    # If we have only general usage or very few technical matches compared to general usage\n",
    "    if technical_mentions == 0 or (general_usage_count > 0 and technical_mentions / general_usage_count < 0.5):\n",
    "        return {\n",
    "            \"mechanism\": 0,\n",
    "            \"cognitive\": 0,\n",
    "            \"explanatory\": 0,\n",
    "            \"primary_category\": \"general_usage\",\n",
    "            \"confidence\": 1.0,\n",
    "            \"mechanism_count\": mechanism_count,\n",
    "            \"cognitive_count\": cognitive_count,\n",
    "            \"explanatory_count\": explanatory_count,\n",
    "            \"general_usage_count\": general_usage_count,\n",
    "            \"total_attention_mentions\": total_attention_mentions\n",
    "        }\n",
    "    \n",
    "    # Calculate total relevant technical mentions\n",
    "    total_mentions = mechanism_count + cognitive_count + explanatory_count\n",
    "    \n",
    "    if total_mentions == 0:\n",
    "        return {\n",
    "            \"mechanism\": 0,\n",
    "            \"cognitive\": 0,\n",
    "            \"explanatory\": 0,\n",
    "            \"primary_category\": \"unknown\",\n",
    "            \"confidence\": 0,\n",
    "            \"mechanism_count\": 0,\n",
    "            \"cognitive_count\": 0,\n",
    "            \"explanatory_count\": 0,\n",
    "            \"general_usage_count\": general_usage_count,\n",
    "            \"total_attention_mentions\": total_attention_mentions\n",
    "        }\n",
    "    \n",
    "    # Calculate proportions\n",
    "    mechanism_score = mechanism_count / total_mentions\n",
    "    cognitive_score = cognitive_count / total_mentions\n",
    "    explanatory_score = explanatory_count / total_mentions\n",
    "    \n",
    "    # Determine primary category\n",
    "    scores = {\n",
    "        \"mechanism\": mechanism_score,\n",
    "        \"cognitive\": cognitive_score,\n",
    "        \"explanatory\": explanatory_score\n",
    "    }\n",
    "    primary_category = max(scores, key=scores.get)\n",
    "    \n",
    "    # Calculate confidence (difference between highest and second highest score)\n",
    "    sorted_scores = sorted(scores.values(), reverse=True)\n",
    "    if len(sorted_scores) > 1:\n",
    "        confidence = sorted_scores[0] - sorted_scores[1]\n",
    "    else:\n",
    "        confidence = 1.0\n",
    "    \n",
    "    return {\n",
    "        \"mechanism\": mechanism_score,\n",
    "        \"cognitive\": cognitive_score,\n",
    "        \"explanatory\": explanatory_score,\n",
    "        \"primary_category\": primary_category,\n",
    "        \"confidence\": confidence,\n",
    "        \"mechanism_count\": mechanism_count,\n",
    "        \"cognitive_count\": cognitive_count,\n",
    "        \"explanatory_count\": explanatory_count,\n",
    "        \"general_usage_count\": general_usage_count,\n",
    "        \"total_attention_mentions\": total_attention_mentions\n",
    "    }\n",
    "\n",
    "def extract_context_window(text, keyword=\"attention\", window_size=100):\n",
    "    \"\"\"\n",
    "    Extract context windows around keyword mentions\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    text = text.lower()\n",
    "    keyword = keyword.lower()\n",
    "    contexts = []\n",
    "    \n",
    "    # Find all positions of the keyword\n",
    "    start_positions = [m.start() for m in re.finditer(r'\\b' + re.escape(keyword) + r'\\b', text)]\n",
    "    \n",
    "    for pos in start_positions:\n",
    "        # Calculate window boundaries\n",
    "        start = max(0, pos - window_size)\n",
    "        end = min(len(text), pos + len(keyword) + window_size)\n",
    "        \n",
    "        # Extract context\n",
    "        context = text[start:end]\n",
    "        \n",
    "        # Check if this is likely a general usage or technical usage\n",
    "        if not any(re.search(pattern, context) for pattern in general_attention_patterns):\n",
    "            contexts.append({\n",
    "                \"text\": context,\n",
    "                \"is_general_usage\": False\n",
    "            })\n",
    "        else:\n",
    "            contexts.append({\n",
    "                \"text\": context,\n",
    "                \"is_general_usage\": True\n",
    "            })\n",
    "    \n",
    "    return contexts\n",
    "\n",
    "def analyze_attention_papers(papers_df):\n",
    "    \"\"\"\n",
    "    Analyze and classify papers in a DataFrame\n",
    "    \"\"\"\n",
    "    # Print column names to help with debugging\n",
    "    print(\"Columns in DataFrame:\", papers_df.columns.tolist())\n",
    "    \n",
    "    # Create columns for classification results\n",
    "    results = []\n",
    "    \n",
    "    for _, paper in papers_df.iterrows():\n",
    "        try:\n",
    "            # Get the paper text and title\n",
    "            paper_text = paper.get(\"text\", \"\")\n",
    "            paper_title = paper.get(\"title\", \"\")\n",
    "            \n",
    "            # Classify the paper\n",
    "            classification = classify_attention_paper(paper_text, paper_title)\n",
    "            \n",
    "            # Extract context windows for \"attention\" mentions\n",
    "            contexts = extract_context_window(paper_text)\n",
    "            \n",
    "            # Filter out general usage contexts\n",
    "            technical_contexts = [ctx[\"text\"] for ctx in contexts if not ctx[\"is_general_usage\"]]\n",
    "            general_contexts = [ctx[\"text\"] for ctx in contexts if ctx[\"is_general_usage\"]]\n",
    "            \n",
    "            # Sample contexts\n",
    "            sample_technical_context = technical_contexts[0] if technical_contexts else \"\"\n",
    "            sample_general_context = general_contexts[0] if general_contexts else \"\"\n",
    "            \n",
    "            # Create a result dictionary with safe access\n",
    "            result = {\n",
    "                \"conference\": paper.get(\"conference\", \"unknown\"),\n",
    "                \"year\": paper.get(\"year\", 0),\n",
    "                \"title\": paper_title,\n",
    "                \"text\": paper_text,\n",
    "                \"primary_category\": classification.get(\"primary_category\", \"unknown\"),\n",
    "                \"confidence\": classification.get(\"confidence\", 0),\n",
    "                \"mechanism_score\": classification.get(\"mechanism\", 0),\n",
    "                \"cognitive_score\": classification.get(\"cognitive\", 0),\n",
    "                \"explanatory_score\": classification.get(\"explanatory\", 0),\n",
    "                \"mechanism_count\": classification.get(\"mechanism_count\", 0),\n",
    "                \"cognitive_count\": classification.get(\"cognitive_count\", 0),\n",
    "                \"explanatory_count\": classification.get(\"explanatory_count\", 0),\n",
    "                \"general_usage_count\": classification.get(\"general_usage_count\", 0),\n",
    "                \"total_attention_mentions\": classification.get(\"total_attention_mentions\", 0),\n",
    "                \"technical_context_count\": len(technical_contexts),\n",
    "                \"general_context_count\": len(general_contexts),\n",
    "                \"sample_technical_context\": sample_technical_context,\n",
    "                \"sample_general_context\": sample_general_context\n",
    "            }\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paper: {e}\")\n",
    "            # Add a minimal record to keep track of errors\n",
    "            results.append({\n",
    "                \"conference\": paper.get(\"conference\", \"unknown\"),\n",
    "                \"year\": paper.get(\"year\", 0),\n",
    "                \"title\": paper.get(\"title\", \"Error\"),\n",
    "                \"primary_category\": \"error\",\n",
    "                \"confidence\": 0,\n",
    "                \"mechanism_score\": 0,\n",
    "                \"cognitive_score\": 0,\n",
    "                \"explanatory_score\": 0,\n",
    "                \"mechanism_count\": 0,\n",
    "                \"cognitive_count\": 0,\n",
    "                \"explanatory_count\": 0,\n",
    "                \"general_usage_count\": 0,\n",
    "                \"total_attention_mentions\": 0,\n",
    "                \"technical_context_count\": 0,\n",
    "                \"general_context_count\": 0,\n",
    "                \"sample_technical_context\": \"\",\n",
    "                \"sample_general_context\": f\"Error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    # Create a new DataFrame with results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Analyze our attention papers\n",
    "try:\n",
    "    print(\"Analyzing papers for different senses of 'attention'...\")\n",
    "    attention_classification = analyze_attention_papers(attention_df)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nPaper Classification Summary:\")\n",
    "    print(attention_classification[\"primary_category\"].value_counts())\n",
    "    \n",
    "    # Calculate percentage of papers with general vs technical usage\n",
    "    total_papers = len(attention_classification)\n",
    "    general_usage_papers = len(attention_classification[attention_classification[\"primary_category\"] == \"general_usage\"])\n",
    "    technical_usage_papers = total_papers - general_usage_papers\n",
    "    \n",
    "    print(f\"\\nGeneral vs Technical Usage:\")\n",
    "    print(f\"General language usage: {general_usage_papers} papers ({general_usage_papers/total_papers*100:.1f}%)\")\n",
    "    print(f\"Technical AI usage: {technical_usage_papers} papers ({technical_usage_papers/total_papers*100:.1f}%)\")\n",
    "    \n",
    "    # Show distribution by conference (excluding general usage)\n",
    "    technical_papers = attention_classification[attention_classification[\"primary_category\"] != \"general_usage\"]\n",
    "    if not technical_papers.empty:\n",
    "        conference_category_pivot = pd.pivot_table(\n",
    "            technical_papers, \n",
    "            index=\"conference\", \n",
    "            columns=\"primary_category\", \n",
    "            aggfunc=\"size\", \n",
    "            fill_value=0\n",
    "        )\n",
    "        print(\"\\nDistribution of technical usage by conference:\")\n",
    "        print(conference_category_pivot)\n",
    "    \n",
    "    # Show distribution by year (evolution over time)\n",
    "    if not technical_papers.empty:\n",
    "        year_category_pivot = pd.pivot_table(\n",
    "            technical_papers, \n",
    "            index=\"year\", \n",
    "            columns=\"primary_category\", \n",
    "            aggfunc=\"size\", \n",
    "            fill_value=0\n",
    "        )\n",
    "        print(\"\\nEvolution of technical usage over time:\")\n",
    "        print(year_category_pivot)\n",
    "    \n",
    "    # Show average confidence by category\n",
    "    category_confidence = attention_classification.groupby(\"primary_category\")[\"confidence\"].mean()\n",
    "    print(\"\\nAverage confidence by category:\")\n",
    "    print(category_confidence)\n",
    "    \n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during analysis: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication by Research Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running domain analysis on previously classified attention papers...\n",
      "Classifying papers by AI domain (LLM, CV, NLP, RL)...\n",
      "Note: Only classifying papers with direct domain identifiers.\n",
      "\n",
      "Domain Classification Summary:\n",
      "domain\n",
      "CV     2799\n",
      "LLM    1905\n",
      "RL     1743\n",
      "NLP      61\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification rate: 100.0% (6508/6508 papers)\n",
      "\n",
      "Distribution by conference:\n",
      "domain        CV  LLM  NLP   RL\n",
      "conference                     \n",
      "CVPR        2046  816   10  532\n",
      "ICLR         217  456   22  526\n",
      "NIPS         536  633   29  685\n",
      "\n",
      "Evolution over time:\n",
      "domain   CV  LLM  NLP   RL\n",
      "year                      \n",
      "2010      1    0    0    1\n",
      "2011      0    0    0    1\n",
      "2012      0    1    0    3\n",
      "2013     11    0    0    6\n",
      "2014      6    0    0    8\n",
      "2015     11    2    0   17\n",
      "2016     41    3    3   28\n",
      "2017     90    4    9   40\n",
      "2018     26   11    4   56\n",
      "2019     61   30    6   69\n",
      "2020     66   61    5  120\n",
      "2021    414  220   14  261\n",
      "2022    600  435    7  325\n",
      "2023    798  598   11  464\n",
      "2024    674  540    2  344\n",
      "\n",
      "Domain vs Attention Category:\n",
      "attention_category  cognitive  explanatory  general_usage  mechanism\n",
      "domain                                                              \n",
      "CV                        104          496             20       2179\n",
      "LLM                        13           73              3       1816\n",
      "NLP                         6            8              2         45\n",
      "RL                        120          348             30       1245\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Define clear domain identifiers - direct and specific terms that strongly indicate the domain\n",
    "domain_identifiers = {\n",
    "    \"LLM\": [\"large language model\", \"llm\", \"gpt\", \"language model\", \"transformer\",\n",
    "           \"generative pre-trained\"],\n",
    "    \n",
    "    \"CV\": [\"computer vision\", \"image recognition\", \"object detection\", \"image classification\", \n",
    "          \"image segmentation\", \"convolutional neural network\", \"cnn\", \"vision transformer\"],\n",
    "    \n",
    "    \"NLP\": [\"natural language processing\", \"nlp\", \"text classification\", \"word embedding\"],\n",
    "    \n",
    "    \"RL\": [\"reinforcement learning\", \"rl\", \"q-learning\", \"policy gradient\"]\n",
    "}\n",
    "\n",
    "def classify_ai_domain(text, title=\"\"):\n",
    "    \"\"\"\n",
    "    Classify a paper into LLM, CV, NLP, or RL domains using only direct identifiers.\n",
    "    If no direct identifiers are found, classify as \"unknown\".\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {\n",
    "            \"domain\": \"unknown\",\n",
    "            \"confidence\": 0,\n",
    "            \"keywords_found\": []\n",
    "        }\n",
    "    \n",
    "    # Combine title and text, with title weighted more\n",
    "    full_text = (title + \" \" + title + \" \" + text).lower()\n",
    "    \n",
    "    # Check for direct domain identifiers\n",
    "    domain_matches = {}\n",
    "    domain_terms_found = {}\n",
    "    \n",
    "    for domain, identifiers in domain_identifiers.items():\n",
    "        terms_found = []\n",
    "        count = 0\n",
    "        for term in identifiers:\n",
    "            occurrences = full_text.count(term.lower())\n",
    "            if occurrences > 0:\n",
    "                count += occurrences\n",
    "                terms_found.append(term)\n",
    "        \n",
    "        domain_matches[domain] = count\n",
    "        domain_terms_found[domain] = terms_found\n",
    "    \n",
    "    # If we have direct identifier matches, use those to determine domain\n",
    "    if any(count > 0 for count in domain_matches.values()):\n",
    "        # Find domain with most matches\n",
    "        best_domain = max(domain_matches, key=domain_matches.get)\n",
    "        \n",
    "        return {\n",
    "            \"domain\": best_domain,\n",
    "            \"match_count\": domain_matches[best_domain],\n",
    "            \"confidence\": 1.0,  # High confidence since we matched direct identifiers\n",
    "            \"keywords_found\": domain_terms_found[best_domain]\n",
    "        }\n",
    "    \n",
    "    # If no direct identifiers found, return unknown\n",
    "    return {\n",
    "        \"domain\": \"unknown\",\n",
    "        \"match_count\": 0,\n",
    "        \"confidence\": 0,\n",
    "        \"keywords_found\": []\n",
    "    }\n",
    "\n",
    "def analyze_domains(papers_df):\n",
    "    \"\"\"\n",
    "    Analyze and classify papers by AI domain using only direct identifiers\n",
    "    \"\"\"\n",
    "    print(\"Classifying papers by AI domain (LLM, CV, NLP, RL)...\")\n",
    "    print(\"Note: Only classifying papers with direct domain identifiers.\")\n",
    "    \n",
    "    # Create columns for classification results\n",
    "    results = []\n",
    "    \n",
    "    for _, paper in papers_df.iterrows():\n",
    "        try:\n",
    "            # Get the paper text and title\n",
    "            paper_text = paper.get(\"text\", \"\")\n",
    "            paper_title = paper.get(\"title\", \"\")\n",
    "            \n",
    "            # Classify the paper by AI domain\n",
    "            domain_classification = classify_ai_domain(paper_text, paper_title)\n",
    "            \n",
    "            # Get attention category if available\n",
    "            attention_category = paper.get(\"primary_category\", \"unknown\")\n",
    "            \n",
    "            # Create a result dictionary\n",
    "            result = {\n",
    "                \"conference\": paper.get(\"conference\", \"unknown\"),\n",
    "                \"year\": paper.get(\"year\", 0),\n",
    "                \"title\": paper_title,\n",
    "                \"domain\": domain_classification.get(\"domain\", \"unknown\"),\n",
    "                \"match_count\": domain_classification.get(\"match_count\", 0),\n",
    "                \"keywords\": \", \".join(domain_classification.get(\"keywords_found\", [])[:5]),\n",
    "                \"attention_category\": attention_category\n",
    "            }\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing paper: {e}\")\n",
    "            # Add a minimal record to keep track of errors\n",
    "            results.append({\n",
    "                \"conference\": paper.get(\"conference\", \"unknown\"),\n",
    "                \"year\": paper.get(\"year\", 0),\n",
    "                \"title\": paper.get(\"title\", \"Error\"),\n",
    "                \"domain\": \"error\",\n",
    "                \"match_count\": 0,\n",
    "                \"keywords\": \"\",\n",
    "                \"attention_category\": paper.get(\"primary_category\", \"unknown\")\n",
    "            })\n",
    "    \n",
    "    # Create a new DataFrame with results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Main analysis function that runs on the attention classification data\n",
    "def run_domain_analysis(attention_classification_df):\n",
    "    \"\"\"\n",
    "    Run the domain analysis on the previously classified attention papers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Classify papers by AI domain\n",
    "        domain_classification = analyze_domains(attention_classification_df)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nDomain Classification Summary:\")\n",
    "        print(domain_classification[\"domain\"].value_counts())\n",
    "        \n",
    "        # Calculate percentage of classified papers\n",
    "        total_papers = len(domain_classification)\n",
    "        classified_papers = len(domain_classification[domain_classification[\"domain\"] != \"unknown\"])\n",
    "        classification_rate = classified_papers / total_papers * 100 if total_papers > 0 else 0\n",
    "        \n",
    "        print(f\"\\nClassification rate: {classification_rate:.1f}% ({classified_papers}/{total_papers} papers)\")\n",
    "        \n",
    "        # Show distribution by conference\n",
    "        conference_domain_pivot = pd.pivot_table(\n",
    "            domain_classification, \n",
    "            index=\"conference\", \n",
    "            columns=\"domain\", \n",
    "            aggfunc=\"size\", \n",
    "            fill_value=0\n",
    "        )\n",
    "        print(\"\\nDistribution by conference:\")\n",
    "        print(conference_domain_pivot)\n",
    "        \n",
    "        # Show distribution by year (evolution over time)\n",
    "        year_domain_pivot = pd.pivot_table(\n",
    "            domain_classification, \n",
    "            index=\"year\", \n",
    "            columns=\"domain\", \n",
    "            aggfunc=\"size\", \n",
    "            fill_value=0\n",
    "        )\n",
    "        print(\"\\nEvolution over time:\")\n",
    "        print(year_domain_pivot)\n",
    "        \n",
    "        # Cross-tabulate domain vs attention category\n",
    "        if \"attention_category\" in domain_classification.columns:\n",
    "            domain_attention_pivot = pd.pivot_table(\n",
    "                domain_classification,\n",
    "                index=\"domain\",\n",
    "                columns=\"attention_category\",\n",
    "                aggfunc=\"size\",\n",
    "                fill_value=0\n",
    "            )\n",
    "            print(\"\\nDomain vs Attention Category:\")\n",
    "            print(domain_attention_pivot)\n",
    "        \n",
    "        return domain_classification, conference_domain_pivot, year_domain_pivot, domain_examples\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during domain analysis: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "try:\n",
    "    # Check if we have the attention classification data from the previous step\n",
    "    if 'attention_classification' in globals():\n",
    "        print(\"Running domain analysis on previously classified attention papers...\")\n",
    "        domain_classification, conference_domain_pivot, year_domain_pivot, domain_examples = run_domain_analysis(attention_classification)\n",
    "        \n",
    "    else:\n",
    "        print(\"Error: attention_classification not found. Please run the attention classification step first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in main execution: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
